{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.llms import GooglePalm\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "ENV = dotenv_values(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store_from_docs():\n",
    "   docs = []\n",
    "   for pdf in os.listdir(\"../pdf_EN\"):\n",
    "      loader = PyPDFLoader(f\"../pdf_EN/{pdf}\")\n",
    "      docs.extend(loader.load())\n",
    "\n",
    "   text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=30)\n",
    "   chunked_docs = text_splitter.split_documents(docs)\n",
    "   \n",
    "   vector_db = Chroma.from_documents(chunked_docs, embedding=HuggingFaceEmbeddings(), persist_directory=\"../vector_store_EN\")\n",
    "   vector_db.persist()\n",
    "\n",
    "   return vector_db   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_db = get_vector_store_from_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Agent + QA Retrievals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GooglePalm(temperature=0, google_api_key=ENV[\"PALM_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = RetrievalQA.from_chain_type(\n",
    "   llm=llm,\n",
    "   chain_type=\"stuff\",\n",
    "   retriever=vector_store_db.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper(serpapi_api_key=ENV[\"SERP_API_KEY\"])\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"ReACT\",\n",
    "        func=rag.run,\n",
    "        description=\"useful for when you need to answer questions about synergizing reasoning and acting in language models.\",\n",
    "        return_direct=True\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "   tools=tools,\n",
    "   llm=llm,\n",
    "   agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "   verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to know what biden said about ketanji brown jackson in the state of the union address\n",
      "Action: Search\n",
      "Action Input: biden said about ketanji brown jackson in the state of the union address\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mBrilliant. A brilliant legal mind with deep knowledge of the law. And a judicial temperament — which was equally important, in my view — that's calm and in command. And a humility that allows so many Americans to see themselves in Ketanji Brown Jackson.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Brilliant. A brilliant legal mind with deep knowledge of the law. And a judicial temperament — which was equally important, in my view — that's calm and in command. And a humility that allows so many Americans to see themselves in Ketanji Brown Jackson.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Brilliant. A brilliant legal mind with deep knowledge of the law. And a judicial temperament — which was equally important, in my view — that's calm and in command. And a humility that allows so many Americans to see themselves in Ketanji Brown Jackson.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What did biden say about ketanji brown jackson in the state of the union address?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use ReACT to answer this question\n",
      "Action: ReACT\n",
      "Action Input: synergizing reasoning and acting in language models\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe paper proposes a method called ReAct, which stands for REasoning and ACTing in Language Models. ReAct allows LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two. Reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with and gather additional information from external sources such as knowledge bases or environments. ReAct is evaluated on a diverse set of language and decision making tasks, and it demonstrates its effectiveness over state-of-the-art baselines in addition to improved human interpretability and trustworthiness.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The paper proposes a method called ReAct, which stands for REasoning and ACTing in Language Models. ReAct allows LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two. Reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with and gather additional information from external sources such as knowledge bases or environments. ReAct is evaluated on a diverse set of language and decision making tasks, and it demonstrates its effectiveness over state-of-the-art baselines in addition to improved human interpretability and trustworthiness.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is synergizing reasoning and acting in language models?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
